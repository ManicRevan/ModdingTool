class AITextureGenerator {
  constructor(config) {
    this.config = config;
    this.modelCache = {};
    this.tf = require('@tensorflow/tfjs-node');
    
    // Initialize GPU if available
    if (config.generation.useGPUAcceleration) {
      try {
        this.tf.setBackend('tensorflow');
        logger.info('TensorFlow using GPU backend');
      } catch (error) {
        logger.warn('Failed to use GPU backend, falling back to CPU:', error);
        this.tf.setBackend('cpu');
      }
    }
  }
  
  async initialize() {
    // Load or download StyleGAN model if using built-in models
    if (this.config.generation.usePretrainedModels) {
      await this.loadOrDownloadModel('styleGAN_textures');
    }
    
    return true;
  }
  
  async loadOrDownloadModel(modelName) {
    const modelDir = path.join(this.config.paths.tempPath, 'models', modelName);
    
    if (!fs.existsSync(modelDir)) {
      logger.info(`Downloading ${modelName} model...`);
      await fs.ensureDir(modelDir);
      
      // In a real implementation, this would download from a model repository
      // For now, this is a placeholder
      const modelUrl = this.getModelUrl(modelName);
      await this.downloadModel(modelUrl, modelDir);
    }
    
    logger.info(`Loading ${modelName} model...`);
    try {
      this.modelCache[modelName] = await this.tf.loadGraphModel(`file://${modelDir}/model.json`);
      logger.info(`${modelName} model loaded successfully`);
    } catch (error) {
      logger.error(`Error loading ${modelName} model:`, error);
      throw error;
    }
  }
  
  getModelUrl(modelName) {
    // In a real implementation, this would point to actual model URLs
    const modelUrls = {
      'styleGAN_textures': 'https://example.com/models/stylegan_textures.zip'
    };
    
    return modelUrls[modelName] || null;
  }
  
  async downloadModel(modelUrl, outputDir) {
    // Placeholder for model downloading
    // In a real implementation, this would download and extract model files
    
    // Mock model files for demonstration
    await fs.writeFile(path.join(outputDir, 'model.json'), JSON.stringify({
      format: 'graph-model',
      generatedBy: 'TensorFlow.js',
      convertedBy: 'TensorFlow.js Converter',
      modelTopology: {},
      weightsManifest: [
        {
          paths: ['group1-shard1of1.bin'],
          weights: []
        }
      ]
    }));
    
    await fs.writeFile(path.join(outputDir, 'group1-shard1of1.bin'), Buffer.alloc(1024));
  }
  
  async generateTexture(params) {
    const { textureType, resolution, seed, style } = params;
    const noiseScale = params.noiseScale || 1.0;
    const variation = params.variation || 0.5;
    
    // Check if we should use external API or local model
    if (this.config.api.imageGeneration.apiKey && params.useAPI !== false) {
      return this.generateTextureWithAPI(params);
    }
    
    // Generate with local StyleGAN model
    return this.generateTextureWithStyleGAN(params);
  }
  
  async generateTextureWithAPI(params) {
    const { textureType, resolution, prompt, negativePrompt } = params;
    
    // Construct a detailed prompt based on texture type
    let fullPrompt = prompt || this.constructPrompt(textureType);
    let fullNegativePrompt = negativePrompt || this.constructNegativePrompt(textureType);
    
    logger.info(`Generating texture with API: ${fullPrompt}`);
    
    // Use Stability AI API
    try {
      const response = await axios({
        method: 'post',
        url: 'https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image',
        headers: {
          'Content-Type': 'application/json',
          Accept: 'application/json',
          Authorization: `Bearer ${this.config.api.imageGeneration.apiKey}`
        },
        data: {
          text_prompts: [
            {
              text: fullPrompt,
              weight: 1.0
            },
            {
              text: fullNegativePrompt,
              weight: -1.0
            }
          ],
          cfg_scale: 7.0,
          height: resolution,
          width: resolution,
          samples: 1,
          steps: 30
        },
        responseType: 'json'
      });
      
      // Process response
      if (response.data && response.data.artifacts && response.data.artifacts.length > 0) {
        const base64Image = response.data.artifacts[0].base64;
        const imageBuffer = Buffer.from(base64Image, 'base64');
        
        // Write to temp file
        const outputPath = path.join(os.tmpdir(), `texture_${Date.now()}.png`);
        await fs.writeFile(outputPath, imageBuffer);
        
        // Post-process the texture if needed
        return this.postProcessTexture(outputPath, textureType);
      } else {
        throw new Error('No image generated in API response');
      }
    } catch (error) {
      logger.error('Error generating texture with API:', error);
      // Fall back to local generation
      return this.generateTextureWithStyleGAN(params);
    }
  }
  
  constructPrompt(textureType) {
    // Create appropriate prompt based on texture type
    const prompts = {
      'diffuse': 'highly detailed material texture, seamless surface texture, 8k PBR material, photorealistic, high resolution, sharp details',
      'normal': 'seamless normal map, detailed surface bumps and crevices, 8k PBR normal map, blue and purple hues',
      'specular': 'seamless specular map, reflective surface, varying sheen, 8k PBR specular map, greyscale',
      'roughness': 'seamless roughness map, varying surface texture, grainy and smooth areas, 8k PBR roughness map, greyscale',
      'metal': 'seamless metal texture, worn scratched metal surface, industrial material, 8k PBR metal texture',
      'rock': 'detailed stone surface, seamless rock texture, natural geological formation, rugged surface, 8k PBR rock texture',
      'fabric': 'detailed fabric weave, seamless textile texture, cloth material, 8k PBR fabric texture',
      'wood': 'detailed wood grain, seamless timber texture, natural material, 8k PBR wood texture',
      'skin': 'detailed human skin texture, seamless skin pores, realistic human epidermis, 8k PBR skin texture',
      'cybernetic': 'detailed cybernetic surface, seamless futuristic texture, high-tech implant material, glowing circuits, 8k PBR texture'
    };
    
    return prompts[textureType] || prompts['diffuse'];
  }
  
  constructNegativePrompt(textureType) {
    return 'blurry, distorted, warped, low resolution, tiling artifacts, visible seams, text, watermark, signature, copyright';
  }
  
  async generateTextureWithStyleGAN(params) {
    const { textureType, resolution, seed } = params;
    
    // Ensure we have a StyleGAN model loaded
    if (!this.modelCache['styleGAN_textures']) {
      await this.loadOrDownloadModel('styleGAN_textures');
    }
    
    // Generate random latent vector or use seed
    let latentVector;
    if (seed !== undefined) {
      // Create deterministic latent vector based on seed
      const rng = new Math.seedrandom(seed.toString());
      const latentArray = Array.from({ length: 512 }, () => rng() * 2 - 1);
      latentVector = this.tf.tensor2d([latentArray], [1, 512]);
    } else {
      // Random latent vector
      latentVector = this.tf.randomNormal([1, 512]);
    }
    
    // Create conditioning based on texture type
    const typeEncoding = this.getTextureTypeEncoding(textureType);
    const conditioning = this.tf.tensor2d([typeEncoding], [1, typeEncoding.length]);
    
    // Run inference
    const model = this.modelCache['styleGAN_textures'];
    const result = model.predict([latentVector, conditioning]);
    
    // Convert to image
    const imageData = await this.tf.browser.toPixels(
      this.tf.clipByValue(
        this.tf.add(
          this.tf.mul(result, this.tf.scalar(0.5)),
          this.tf.scalar(0.5)
        ),
        0,
        1
      )
    );
    
    // Create sharp image and resize if needed
    const rawSize = Math.sqrt(imageData.length / 4); // 4 channels (RGBA)
    const image = sharp(Buffer.from(imageData), {
      raw: {
        width: rawSize,
        height: rawSize,
        channels: 4
      }
    });
    
    // Resize to requested resolution
    const resizedImage = image.resize(resolution, resolution);
    
    // Save to temporary file
    const outputPath = path.join(os.tmpdir(), `texture_${Date.now()}.png`);
    await resizedImage.toFile(outputPath);
    
    // Post-process the texture based on type
    return this.postProcessTexture(outputPath, textureType);
  }
  
  getTextureTypeEncoding(textureType) {
    // One-hot encoding for different texture types
    const encodings = {
      'diffuse': [1, 0, 0, 0, 0],
      'normal': [0, 1, 0, 0, 0],
      'specular': [0, 0, 1, 0, 0],
      'roughness': [0, 0, 0, 1, 0],
      'metal': [1, 0, 0, 0, 1],
      'rock': [1, 0, 0, 1, 0],
      'fabric': [1, 0, 1, 0, 0],
      'wood': [1, 1, 0, 0, 0],
      'skin': [1, 0, 0, 0, 0],
      'cybernetic': [0, 0, 0, 0, 1]
    };
    
    return encodings[textureType] || encodings['diffuse'];
  }
  
  async postProcessTexture(inputPath, textureType) {
    // Apply specific post-processing based on texture type
    let image = sharp(inputPath);
    
    switch (textureType) {
      case 'normal':
        // Ensure proper color range for normal maps (centered around #8080FF)
        image = image.tint({ r: 128, g: 128, b: 255 });
        break;
        
      case 'specular':
      case 'roughness':
        // Convert to grayscale for spec/roughness maps
        image = image.grayscale();
        break;
        
      case 'metal':
        // Enhance contrast for metal textures
        image = image.gamma(1.2).contrast(1.2);
        break;
        
      case 'cybernetic':
        // Add glow effect for cybernetic textures
        image = image.modulate({
          brightness: 1.1,
          saturation: 1.3
        });
        break;
    }
    
    // Make sure texture is tileable (seamless)
    image = await this.makeSeamless(image);
    
    // Save to output file
    const outputPath = path.join(os.tmpdir(), `processed_texture_${Date.now()}.png`);
    await image.toFile(outputPath);
    
    return outputPath;
  }
  
  async makeSeamless(image) {
    // Get image metadata
    const metadata = await image.metadata();
    const { width, height } = metadata;
    
    // Create a temporary file for the input image
    const inputPath = path.join(os.tmpdir(), `texture_seamless_input_${Date.now()}.png`);
    await image.toFile(inputPath);
    
    // Use ImageMagick to make the texture seamless
    // This uses the "seamless" option which makes edges wrap
    const outputPath = path.join(os.tmpdir(), `texture_seamless_${Date.now()}.png`);
    
    return new Promise((resolve, reject) => {
      exec(`magick "${inputPath}" -virtual-pixel mirror -blur 0x1 -sample ${width}x${height}! "${outputPath}"`, (error) => {
        if (error) {
          logger.error('Error making texture seamless:', error);
          // Fall back to original image
          resolve(inputPath);
        } else {
          resolve(outputPath);
        }
      });
    });
  }
}